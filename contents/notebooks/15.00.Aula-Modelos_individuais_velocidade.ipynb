{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<!--HEADER-->\n",
    "[*Notas sobre modelagem da epidemia de Covid-19*](https://github.com/rmsrosa/modcovid19) / [*IM-UFRJ*](https://www.im.ufrj.br)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<!--BADGES-->\n",
    "<a href=\"../slides/15.00.Aula-Modelos_individuais_velocidade.slides.html\" target=\"_blank\"><img align=\"left\" src=\"https://img.shields.io/badge/local-slides-darkgreen\" alt=\"localslides\" title=\"Local Slides\"></a>\n",
    "&nbsp;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<!--NAVIGATOR-->\n",
    "[<- Modelos individuais - convergência em redes completas](14.00.Aula-Modelos_individuais_convergencia_redes_completas.ipynb) | [Página Inicial](00.00-Pagina_Inicial.ipynb) | [Modelos individuais - reformulação da implementação ->](16.00.Aula-Modelos_individuais_reformulacao.ipynb)\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Modelos individuais - velocidade de processsamento\n",
    "\n",
    "- Analisar o custo computacional de cada linha de cógido da função de passo de tempo.\n",
    "\n",
    "- Analisar opções de aceleração de cada uma dessas linhas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "**Importando bibliotecas e definindo funções a serem usadas abaixo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import datetime # date and time tools\n",
    "\n",
    "import os, sys\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from numba import njit, prange\n",
    "import threading\n",
    "\n",
    "import math\n",
    "from timeit import repeat\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import io, base64\n",
    "from IPython.display import Image, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "import episiming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Atualização mais recente do kernel: 20/May/2020\n"
     ]
    }
   ],
   "source": [
    "dt_string = datetime.datetime.now().strftime(\"%d/%b/%Y\")\n",
    "print(f\"Atualização mais recente do kernel: {dt_string}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "sns.set_style(\"darkgrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Gargalos\n",
    "\n",
    "### Passo de tempo\n",
    "\n",
    "Aqui o código atual de cada passo de tempo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def passo_vetorial(pop_estado, redes, redes_tx_transmissao,\n",
    "                   pop_fator_tx_transmissao_c, prob_nao_recuperacao,\n",
    "                   pop_posicoes, f_kernel, dt):\n",
    "\n",
    "    num_pop = len(pop_estado)\n",
    "\n",
    "    pop_suscetiveis = np.select([pop_estado==1], [pop_estado])\n",
    "\n",
    "    pop_infectados = np.select([pop_estado==2], [pop_estado])/2\n",
    "    \n",
    "    contatos_de_risco_rs = np.zeros([len(redes_tx_transmissao), num_pop])\n",
    "\n",
    "    for j in range(len(redes_tx_transmissao)):\n",
    "        for (i,k) in redes[j].edges:\n",
    "            if pop_infectados[k] and pop_suscetiveis[i]:\n",
    "                contatos_de_risco_rs[j][i] += 1\n",
    "            elif pop_infectados[i] and pop_suscetiveis[k]:\n",
    "                contatos_de_risco_rs[j][k] += 1\n",
    "               \n",
    "    contatos_de_risco_c = np.array(\n",
    "            [np.dot(pop_infectados,\n",
    "                    f_kernel(np.linalg.norm(pop_posicoes - pop_posicoes[i], \n",
    "                             axis=1)\n",
    "                            )\n",
    "                    )\n",
    "             for i in range(num_pop)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    \n",
    "    lambda_rate = ((redes_tx_transmissao * contatos_de_risco_rs).sum(axis=0) +\n",
    "                   pop_fator_tx_transmissao_c * contatos_de_risco_c)\n",
    "    \n",
    "    prob_nao_contagio = np.exp(-dt*lambda_rate)                             \n",
    "\n",
    "    sorteio = np.random.rand(num_pop)\n",
    "\n",
    "    pop_novos_infectados = np.select([sorteio > prob_nao_contagio], [np.ones(num_pop)])\n",
    "\n",
    "    sorteio = np.random.rand(num_pop)\n",
    "\n",
    "    pop_novos_recuperados = np.select([pop_infectados * sorteio > prob_nao_recuperacao], \n",
    "                                      [np.ones(num_pop)])\n",
    "\n",
    "    return pop_estado + pop_novos_infectados + pop_novos_recuperados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Cálculo da população\n",
    "\n",
    "O cálculo de `num_pop` a partir de `pop_estado` é ridiculamente rápido. De qualquer forma, podemos incluí-lo como argumento. Para vermos a diferença, podemos comparar o custo em se calcular `num_pop` e entre passar ou não como parâmetro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115 ns ± 14.3 ns per loop (mean ± std. dev. of 7 runs, 10000000 loops each)\n",
      "123 ns ± 1.38 ns per loop (mean ± std. dev. of 7 runs, 10000000 loops each)\n",
      "152 ns ± 2.01 ns per loop (mean ± std. dev. of 7 runs, 10000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "n_pop = 10000\n",
    "pop_estado = np.random.randint(low=1, high=3, size = n_pop)\n",
    "\n",
    "def f(a):\n",
    "    pass\n",
    "\n",
    "def g(num_pop, a):\n",
    "    pass\n",
    "\n",
    "%timeit len(pop_estado)\n",
    "\n",
    "%timeit f(pop_estado)\n",
    "%timeit g(n_pop, pop_estado)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Linhas de código com puro numpy\n",
    "\n",
    "As linhas\n",
    "\n",
    "```python\n",
    "    pop_suscetiveis = np.select([pop_estado==1], [pop_estado])\n",
    "\n",
    "    pop_infectados = np.select([pop_estado==2], [pop_estado])/2\n",
    "    \n",
    "    contatos_de_risco_rs = np.zeros([len(redes_tx_transmissao), num_pop])\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    lambda_rate = ((redes_tx_transmissao * contatos_de_risco_rs).sum(axis=0) +\n",
    "                   pop_fator_tx_transmissao_c * contatos_de_risco_c)\n",
    "    \n",
    "    prob_nao_contagio = np.exp(-dt*lambda_rate)                             \n",
    "\n",
    "    sorteio = np.random.rand(num_pop)\n",
    "\n",
    "    pop_novos_infectados = np.select([sorteio > prob_nao_contagio], [np.ones(num_pop)])\n",
    "\n",
    "    sorteio = np.random.rand(num_pop)\n",
    "\n",
    "    pop_novos_recuperados = np.select([pop_infectados * sorteio > prob_nao_recuperacao], \n",
    "                                      [np.ones(num_pop)])\n",
    "\n",
    "    return pop_estado + pop_novos_infectados + pop_novos_recuperados\n",
    "\n",
    "```\n",
    "\n",
    "são todas tratadas diretamente pelo `numpy`, portanto, já são bastante eficientes e paralelizadas (sob condições normais do sistema).\n",
    "\n",
    "É claro que podemos ganhar mais paralelizando o conjunto todo dessas linhas.\n",
    "\n",
    "E veremos, também, que o `np.select` não é eficiente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Gargalos\n",
    "\n",
    "Os dois gargalos, no entanto, estão no cálculo dos contatos de risco, tanto das redes fixas (residencial e de local de escola/trabalho) como da comunidade.\n",
    "\n",
    "O problema é que ambas envolvem ciclos *(loops)* em python. E não vejo como torná-los códigos tratados diretamente pelo `numpy`.\n",
    "\n",
    "```python\n",
    "    for j in range(len(redes_tx_transmissao)):\n",
    "        for (i,k) in redes[j].edges:\n",
    "            if pop_infectados[k] and pop_suscetiveis[i]:\n",
    "                contatos_de_risco_rs[j][i] += 1\n",
    "            elif pop_infectados[i] and pop_suscetiveis[k]:\n",
    "                contatos_de_risco_rs[j][k] += 1\n",
    "               \n",
    "    contatos_de_risco_c = np.array(\n",
    "            [np.dot(pop_infectados,\n",
    "                    f_kernel(np.linalg.norm(pop_posicoes - pop_posicoes[i], \n",
    "                             axis=1)\n",
    "                            )\n",
    "                    )\n",
    "             for i in range(num_pop)\n",
    "            ]\n",
    "        )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Custo computacional\n",
    "\n",
    "Para ilustrar o custo computacional de cada termo acima, vamos considerar o cenário de 350 habitantes usado anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "cenario_pop_350 = episiming.cenarios.Pop350()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Definindo as variáveis usadas pela função "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "dt = 1\n",
    "pop_estado = cenario_pop_350.pop_estado_0\n",
    "redes = cenario_pop_350.redes\n",
    "redes_tx_transmissao = cenario_pop_350.redes_tx_transmissao\n",
    "pop_fator_tx_transmissao_c = cenario_pop_350.pop_fator_tx_transmissao_c\n",
    "prob_nao_recuperacao = np.exp(-dt*cenario_pop_350.gamma)\n",
    "pop_posicoes = cenario_pop_350.pop_posicoes\n",
    "f_kernel = cenario_pop_350.f_kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Para o cálculo do tempo, vamos definir, ainda, funções para os códigos que consideramos \"gargalos\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def get_contatos_de_risco_rs(num_pop, pop_suscetiveis, pop_infectados, redes):\n",
    "\n",
    "    contatos_de_risco_rs = np.zeros([len(redes), num_pop])\n",
    "\n",
    "    for j in range(len(redes)):\n",
    "        for (i,k) in redes[j].edges:\n",
    "            if pop_infectados[k] and pop_suscetiveis[i]:\n",
    "                contatos_de_risco_rs[j][i] += 1\n",
    "            elif pop_infectados[i] and pop_suscetiveis[k]:\n",
    "                contatos_de_risco_rs[j][k] += 1\n",
    "    return contatos_de_risco_rs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def get_contatos_de_risco_c(pop_infectados, pop_posicoes):\n",
    "    contatos_de_risco_c = np.array(\n",
    "            [np.dot(pop_infectados,\n",
    "                    f_kernel(np.linalg.norm(pop_posicoes - pop_posicoes[i], \n",
    "                             axis=1)\n",
    "                            )\n",
    "                    )\n",
    "             for i in range(num_pop)\n",
    "            ]\n",
    "        )\n",
    "    return contatos_de_risco_c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Agora, executamos todos as linhas da função."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "num_pop = len(pop_estado)\n",
    "\n",
    "pop_suscetiveis = np.select([pop_estado==1], [pop_estado])\n",
    "\n",
    "pop_infectados = np.select([pop_estado==2], [pop_estado])/2\n",
    "\n",
    "contatos_de_risco_rs = get_contatos_de_risco_rs(num_pop, pop_suscetiveis, pop_infectados, redes)\n",
    "\n",
    "contatos_de_risco_c = get_contatos_de_risco_c(pop_infectados, pop_posicoes)\n",
    "\n",
    "lambda_rate = ((redes_tx_transmissao * contatos_de_risco_rs).sum(axis=0) + pop_fator_tx_transmissao_c * contatos_de_risco_c)\n",
    "\n",
    "prob_nao_contagio = np.exp(-dt*lambda_rate)                             \n",
    "\n",
    "sorteio = np.random.rand(num_pop)\n",
    "\n",
    "pop_novos_infectados = np.select([sorteio > prob_nao_contagio], [np.ones(num_pop)])\n",
    "\n",
    "sorteio = np.random.rand(num_pop)\n",
    "\n",
    "pop_novos_recuperados = np.select([pop_infectados * sorteio > prob_nao_recuperacao], [np.ones(num_pop)])\n",
    "\n",
    "pop_novo_estado = pop_estado + pop_novos_infectados + pop_novos_recuperados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Com todas as variáveis já calculadas e gravadas na memória, façamos as contagens de tempo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118 ns ± 1.05 ns per loop (mean ± std. dev. of 7 runs, 10000000 loops each)\n",
      "53.8 µs ± 736 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n",
      "59.5 µs ± 1.58 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n",
      "1.96 ms ± 67.4 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "18.9 ms ± 193 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "15.5 µs ± 373 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n",
      "6.79 µs ± 94.1 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n",
      "6.45 µs ± 232 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n",
      "58.7 µs ± 1.1 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n",
      "6.4 µs ± 130 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n",
      "63.5 µs ± 838 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n",
      "2.5 µs ± 47.7 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit num_pop = len(pop_estado)\n",
    "\n",
    "%timeit pop_suscetiveis = np.select([pop_estado==1], [pop_estado])\n",
    "\n",
    "%timeit pop_infectados = np.select([pop_estado==2], [pop_estado])/2\n",
    "\n",
    "%timeit contatos_de_risco_rs = get_contatos_de_risco_rs(num_pop, pop_suscetiveis, pop_infectados, redes)\n",
    "\n",
    "%timeit contatos_de_risco_c = get_contatos_de_risco_c(pop_infectados, pop_posicoes)\n",
    "\n",
    "%timeit lambda_rate = ((redes_tx_transmissao * contatos_de_risco_rs).sum(axis=0) + pop_fator_tx_transmissao_c * contatos_de_risco_c)\n",
    "\n",
    "%timeit prob_nao_contagio = np.exp(-dt*lambda_rate)                             \n",
    "\n",
    "%timeit sorteio = np.random.rand(num_pop)\n",
    "\n",
    "%timeit pop_novos_infectados = np.select([sorteio > prob_nao_contagio], [np.ones(num_pop)])\n",
    "\n",
    "%timeit sorteio = np.random.rand(num_pop)\n",
    "\n",
    "%timeit pop_novos_recuperados = np.select([pop_infectados * sorteio > prob_nao_recuperacao], [np.ones(num_pop)])\n",
    "\n",
    "%timeit pop_novo_estado = pop_estado + pop_novos_infectados + pop_novos_recuperados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Na função toda, gastamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.9 ms ± 511 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit passo_vetorial(pop_estado, redes, redes_tx_transmissao, pop_fator_tx_transmissao_c, prob_nao_recuperacao, pop_posicoes, f_kernel, dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Observe que os cálculos além dos dos contatos de risco têm um custo negligível perto desses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Numba JIT\n",
    "\n",
    "Uma opção é usar o [numba](http://numba.pydata.org/numba-doc/latest/index.html) (veja [A ~5 minute guide to Numba](http://numba.pydata.org/numba-doc/latest/user/5minguide.html)), que é um compilador \"just-in-time\", capaz de transformar um certo conjunto de instruções em python e em numpy diretamente em código executável, no momento da definição da função.\n",
    "\n",
    "A partir daí, qualquer chamada à função irá executar o código compilado da função."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Numba jit na rede de contatos\n",
    "\n",
    "Para simplificar, vamos considerar o cenário de uma rede completa e analisar o tempo necessário para executar diferentes versões do cálculo dos contatos de risco, incluindo versões com o `numba.jit`.\n",
    "\n",
    "Para usar o `numba.jit`, vamos importar o método `njit`, que é o `jit` com a opção `nopython = True`. Esta opção evita que o código \"recaia\" para o python interpretado caso não consiga compilar alguma parte. Vale lembrar, aqui, que só uma parte dos métodos, funções e objetos do python padrão e do numpy funcionam adequadamente no `numba`.\n",
    "\n",
    "Para simplificar ainda mais, vamos assumir, como no caso da rede completa, que há somente uma rede."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "num_pop = 60\n",
    "num_infectados_0 = 6\n",
    "beta = 0.5\n",
    "gamma = 0.2\n",
    "\n",
    "rede_completa = episiming.cenarios.RedeCompleta(num_pop, num_infectados_0, beta, gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "pop_estado = rede_completa.pop_estado_0\n",
    "rede = rede_completa.redes[0]\n",
    "pop_suscetiveis = np.select([pop_estado==1], [pop_estado])\n",
    "pop_infectados = np.select([pop_estado==2], [pop_estado])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def get_contatos_de_risco_nx(num_pop, rede, pop_suscetiveis, pop_infectados):\n",
    "\n",
    "    contatos_de_risco = np.zeros(num_pop)\n",
    "\n",
    "    for (i,k) in rede.edges:\n",
    "        if pop_infectados[k] and pop_suscetiveis[i]:\n",
    "            contatos_de_risco[i] += 1\n",
    "        elif pop_infectados[i] and pop_suscetiveis[k]:\n",
    "            contatos_de_risco[k] += 1\n",
    "\n",
    "    return contatos_de_risco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def get_contatos_de_risco_py(num_pop, pop_suscetiveis, pop_infectados):\n",
    "    contatos_de_risco = np.zeros(num_pop)\n",
    "    for i in range(num_pop):\n",
    "        for k in range(i):\n",
    "            if pop_infectados[k] and pop_suscetiveis[i]:\n",
    "                contatos_de_risco[i] += 1\n",
    "            elif pop_infectados[i] and pop_suscetiveis[k]:\n",
    "                contatos_de_risco[k] += 1\n",
    "    return contatos_de_risco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "@njit\n",
    "def get_contatos_de_risco_jit(num_pop, pop_suscetiveis, pop_infectados):\n",
    "    contatos_de_risco = np.zeros(num_pop)\n",
    "    for i in range(num_pop):\n",
    "        for k in range(i):\n",
    "            if pop_infectados[k] and pop_suscetiveis[i]:\n",
    "                contatos_de_risco[i] += 1\n",
    "            elif pop_infectados[i] and pop_suscetiveis[k]:\n",
    "                contatos_de_risco[k] += 1\n",
    "    return contatos_de_risco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "conexoes = list(rede.edges)\n",
    "def get_contatos_de_risco_cx(num_pop, conexoes, pop_suscetiveis, pop_infectados):\n",
    "    contatos_de_risco = np.zeros(num_pop)\n",
    "    for i, k in conexoes:\n",
    "            if pop_infectados[k] and pop_suscetiveis[i]:\n",
    "                contatos_de_risco[i] += 1\n",
    "            elif pop_infectados[i] and pop_suscetiveis[k]:\n",
    "                contatos_de_risco[k] += 1\n",
    "    return contatos_de_risco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "@njit\n",
    "def get_contatos_de_risco_cx_jit(num_pop, conexoes, pop_suscetiveis, pop_infectados):\n",
    "    contatos_de_risco = np.zeros(num_pop)\n",
    "    for i, k in conexoes:\n",
    "            if pop_infectados[k] and pop_suscetiveis[i]:\n",
    "                contatos_de_risco[i] += 1\n",
    "            elif pop_infectados[i] and pop_suscetiveis[k]:\n",
    "                contatos_de_risco[k] += 1\n",
    "    return contatos_de_risco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from numba.typed import List\n",
    "typed_conexoes = List()\n",
    "[typed_conexoes.append(x) for x in conexoes]\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.57 ms ± 16.6 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "1.08 ms ± 44.3 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "4.86 µs ± 147 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n",
      "954 µs ± 21.1 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "15.2 µs ± 354 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit get_contatos_de_risco_nx(num_pop, rede, pop_suscetiveis, pop_infectados)\n",
    "%timeit get_contatos_de_risco_py(num_pop, pop_suscetiveis, pop_infectados)\n",
    "%timeit get_contatos_de_risco_jit(num_pop, pop_suscetiveis, pop_infectados)\n",
    "%timeit get_contatos_de_risco_cx(num_pop, conexoes, pop_suscetiveis, pop_infectados)\n",
    "%timeit get_contatos_de_risco_cx_jit(num_pop, typed_conexoes, pop_suscetiveis, pop_infectados)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Assim, conseguimor baixar o custo computacional (nesta máquina e neste cenário) do cálculo das conexões de risco da rede de contatos de quase $1.45 \\,\\texttt{ms}$ para algo da ordem de $5 \\,\\mu\\texttt{s}$, usando `get_contatos_de_risco_jit`. Isso é uma redução dramática para menos de $0,4\\%$ em comparação com o custo atual."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numba jit na rede da comunidade\n",
    "\n",
    "Agora, vamos buscar reduzir o custo do cálculo do poder de infecção por conta de contatos aleatórios em toda a comunidade.\n",
    "\n",
    "Construimos as seguintes funções com `njit` e testamos a velocidade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def dist2_jit(x,y):\n",
    "    return (abs(x[0] - y[0])**2 + abs(x[1]-y[1])**2)**.5\n",
    "\n",
    "@njit\n",
    "def f_kernel_jit(d):\n",
    "    return 1.0/(1.0 + (d/1.0)**1.5)\n",
    "\n",
    "@njit\n",
    "def get_contatos_de_risco_c_jit(num_pop, pop_infectados, pop_posicoes):\n",
    "\n",
    "    ret = []\n",
    "    for i in range(num_pop):\n",
    "        f_kernel_i = [\n",
    "            f_kernel_jit(dist2_jit(pop_posicoes[j], pop_posicoes[i])) \n",
    "            for j in range(num_pop)\n",
    "        ]\n",
    "\n",
    "        produto = 0\n",
    "        for j in range(num_pop):\n",
    "            produto += pop_infectados[j] * f_kernel_i[j]\n",
    "\n",
    "        ret.append(produto)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.64 ms ± 57.7 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "310 µs ± 23.2 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "pop_posicoes = rede_completa.pop_posicoes\n",
    "%timeit contatos_de_risco_c = get_contatos_de_risco_c(pop_infectados, pop_posicoes)\n",
    "%timeit get_contatos_de_risco_c_jit(num_pop, pop_infectados, pop_posicoes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Numba jit na seleção de suscetíveis e infectados\n",
    "\n",
    "Após reduzir de milisegundos a microsegundos o custo computacional do cálculo dos contatos de risco na rede social, podemos pensar em acelerar as outras partes, também.\n",
    "\n",
    "O termo mais custoso (contatos com a comunidade) deixaremos para depois. Abaixo, analisamos a aceleração do código de seleção de infectados e suscetíveis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def get_estado_np_select(pop_estado, estado):\n",
    "    return np.select([pop_estado==estado], [pop_estado])/estado\n",
    "\n",
    "def get_estado_np_py(pop_estado, estado):\n",
    "    return np.array([1 if e == estado else 0 for e in pop_estado])\n",
    "\n",
    "@njit\n",
    "def get_estado_jit_np_py(pop_estado, estado):\n",
    "    return np.array([1 if e == estado else 0 for e in pop_estado])\n",
    "\n",
    "@njit\n",
    "def get_estado_jit_loop(pop_estado, estado):\n",
    "    pop_selecionados = np.zeros_like(pop_estado)\n",
    "    for j in range(len(pop_estado)):\n",
    "        if pop_estado[j] == estado:\n",
    "            pop_selecionados[j] = 1\n",
    "    return pop_selecionados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.9 µs ± 554 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n",
      "49.8 µs ± 2.83 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n",
      "1.11 µs ± 21.9 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n",
      "1.05 µs ± 27.1 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "pop_estado = rede_completa.pop_estado_0\n",
    "\n",
    "%timeit get_estado_np_select(pop_estado, 1)\n",
    "%timeit get_estado_np_py(pop_estado, 1)\n",
    "%timeit get_estado_jit_np_py(pop_estado, 1)\n",
    "%timeit get_estado_jit_loop(pop_estado, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Excelente! O `jit` reduziu sensivelmente o custo desse cálculo, também."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Paralelização com o numba\n",
    "\n",
    "Podemos buscar uma aceleração maior ainda implementando alguma forma de paralelização.\n",
    "\n",
    "A seguir, analisamos duas opções."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Paralelização com numba jit e *multi-threading*\n",
    "\n",
    "Podemos combinar o `numba` com multiprocessamento via [threading](https://docs.python.org/3/library/threading.html).\n",
    "\n",
    "Vamos começar com um exemplo adaptado de [Numba: Multi-threading](http://numba.pydata.org/numba-doc/dev/user/examples.html#multi-threading), para ver como ele se sai nessa máquina.\n",
    "\n",
    "Primeiro, montamos uma função que serve de \"envelope\" *(wrapper)*, para paralelizar qualquer função que tenha a característica que agir em cada componente de um *array* separadamente *(element-wise)*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def timefunc(correct, s, func, *args, **kwargs):\n",
    "    \"\"\"\n",
    "    Benchmark *func* and print out its runtime.\n",
    "    \"\"\"\n",
    "    print(s.ljust(20), end=\" \")\n",
    "    # Make sure the function is compiled before we start the benchmark\n",
    "    res = func(*args, **kwargs)\n",
    "    if correct is not None:\n",
    "        assert np.allclose(res, correct), (res, correct)\n",
    "    # time it\n",
    "    print('{:>5.0f} ms'.format(min(repeat(lambda: func(*args, **kwargs),\n",
    "                                          number=5, repeat=2)) * 1000))\n",
    "    return res\n",
    "\n",
    "def make_singlethread(inner_func):\n",
    "    \"\"\"\n",
    "    Run the given function inside a single thread.\n",
    "    \"\"\"\n",
    "    def func(*args):\n",
    "        length = len(args[0])\n",
    "        result = np.empty(length, dtype=np.float64)\n",
    "        inner_func(result, *args)\n",
    "        return result\n",
    "    return func\n",
    "\n",
    "def make_multithread(inner_func, numthreads):\n",
    "    \"\"\"\n",
    "    Run the given function inside *numthreads* threads, splitting its\n",
    "    arguments into equal-sized chunks.\n",
    "    \"\"\"\n",
    "    def func_mt(*args):\n",
    "        length = len(args[0])\n",
    "        result = np.empty(length, dtype=np.float64)\n",
    "        args = (result,) + args\n",
    "        chunklen = (length + numthreads - 1) // numthreads\n",
    "        # Create argument tuples for each input chunk\n",
    "        chunks = [[arg[i * chunklen:(i + 1) * chunklen] for arg in args]\n",
    "                  for i in range(numthreads)]\n",
    "        # Spawn one thread per chunk\n",
    "        threads = [threading.Thread(target=inner_func, args=chunk)\n",
    "                   for chunk in chunks]\n",
    "        for thread in threads:\n",
    "            thread.start()\n",
    "        for thread in threads:\n",
    "            thread.join()\n",
    "        return result\n",
    "    return func_mt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Agora, definimos duas versões de uma função de teste, uma para usar apenas `numpy` e outra para o `numba`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def func_np(a, b):\n",
    "    \"\"\"\n",
    "    Control function using Numpy.\n",
    "    \"\"\"\n",
    "    return np.exp(2.1 * a + 3.2 * b)\n",
    "\n",
    "@njit('void(double[:], double[:], double[:])', nogil=True)\n",
    "def inner_func_nb(result, a, b):\n",
    "    \"\"\"\n",
    "    Function under test.\n",
    "    \"\"\"\n",
    "    for i in range(len(result)):\n",
    "        result[i] = math.exp(2.1 * a[i] + 3.2 * b[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy (1 thread)       100 ms\n",
      "numba (1 thread)        71 ms\n",
      "numba (2 thread)        39 ms\n",
      "numba (3 thread)        37 ms\n",
      "numba (4 thread)        34 ms\n"
     ]
    }
   ],
   "source": [
    "nthreads = os.cpu_count()\n",
    "size = 10**6\n",
    "\n",
    "a = np.random.rand(size)\n",
    "b = np.random.rand(size)\n",
    "\n",
    "func_nb = make_singlethread(inner_func_nb)\n",
    "func_nb_mt = [make_multithread(inner_func_nb, n+1) for n in range(nthreads)]\n",
    "\n",
    "correct = timefunc(None, \"numpy (1 thread)\", func_np, a, b)\n",
    "\n",
    "for n in range(nthreads):\n",
    "    timefunc(correct, f\"numba ({n+1} thread)\", func_nb_mt[n], a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Usando `%timeit`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.6 ms ± 718 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "13.3 ms ± 184 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "8.74 ms ± 452 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "8.14 ms ± 370 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "8.47 ms ± 634 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit func_np(a, b)\n",
    "\n",
    "for n in range(nthreads):\n",
    "    %timeit func_nb_mt[n](a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "@njit\n",
    "def inner_func_nb_jit(a, b):\n",
    "    \"\"\"\n",
    "    Function under test.\n",
    "    \"\"\"\n",
    "    result = np.zeros_like(a)\n",
    "    for i in range(len(result)):\n",
    "        result[i] = math.exp(2.1 * a[i] + 3.2 * b[i])\n",
    "    return result\n",
    "\n",
    "@njit('void(double[:], double[:], double[:])', nogil=True)\n",
    "def inner_func_nb_jit_mt_template(result, a, b):\n",
    "    \"\"\"\n",
    "    Function under test.\n",
    "    \"\"\"\n",
    "    for i in range(len(result)):\n",
    "        result[i] = math.exp(2.1 * a[i] + 3.2 * b[i])\n",
    "\n",
    "inner_func_nb_jit_mt = [make_multithread(inner_func_nb_jit_mt_template, j+1) \n",
    "                          for j in range(os.cpu_count())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempos de np, jit, e jit_mt com 1, 2, 3 e 4 threads\n",
      "18.7 ms ± 182 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "13.3 ms ± 160 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "14.1 ms ± 35.7 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "8.18 ms ± 166 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "7.87 ms ± 157 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "8.28 ms ± 1.55 ms per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "print('Tempos de np, jit, e jit_mt com 1, 2, 3 e 4 threads')\n",
    "%timeit func_np(a,b)\n",
    "%timeit inner_func_nb_jit(a,b)\n",
    "for j in range(os.cpu_count()):\n",
    "    %timeit inner_func_nb_jit_mt[j](a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Ok, é claro que é possível acelerar o código paralelizando via `numba.jit`. Mas parece que ele só usou 2 *cores* adequadamente, não aproveitando que são 2 *threads* por *core* por CPU. E também há a questão do *overhead*.\n",
    "\n",
    "Em relação a *cores* vs *threads*, veja [Optimizing CPU options - CPU cores and threads per CPU core per instance type](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/instance-optimize-cpu.html#cpu-options-supported-instances-values)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Paralelização com numba jit e *prange*\n",
    "\n",
    "Outra opção é via [prange](https://numba.pydata.org/numba-doc/dev/user/parallel.html#explicit-parallel-loops) *(parallel range)* do próprio `numba`, com a opção `parallel=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "@njit(parallel=False)\n",
    "def range_test(a):\n",
    "    s = 0\n",
    "    # Without \"parallel=True\" in the jit-decorator\n",
    "    # the prange statement is equivalent to range\n",
    "    for i in range(a.shape[0]):\n",
    "        s += a[i]\n",
    "    return s\n",
    "\n",
    "@njit(parallel=True)\n",
    "def prange_test(a):\n",
    "    s = 0\n",
    "    # Without \"parallel=True\" in the jit-decorator\n",
    "    # the prange statement is equivalent to range\n",
    "    for i in prange(a.shape[0]):\n",
    "        s += a[i]\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "197 µs ± 8.18 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "75.8 µs ± 28 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "a = np.random.rand(100000)\n",
    "%timeit range_test(a)\n",
    "%timeit prange_test(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Numba jit em paralelo na seleção de suscetíveis e infectados\n",
    "\n",
    "Com essa paralelização em mente, podemos ver se conseguimos reduzir ainda mais os códigos de seleção de infectados e suscetíveis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def make_multithread_mod(inner_func, numthreads):\n",
    "    \"\"\"\n",
    "    Run the given function inside *numthreads* threads, splitting its\n",
    "    arguments into equal-sized chunks.\n",
    "    \"\"\"\n",
    "    def func_mt(pop_estado, estado):\n",
    "        length = len(pop_estado)\n",
    "        result = np.empty(length, dtype=np.float64)\n",
    "        args = (result, pop_estado)\n",
    "        chunklen = (length + numthreads - 1) // numthreads\n",
    "        # Create argument tuples for each input chunk\n",
    "        chunks = [[arg[i * chunklen:(i + 1) * chunklen] for arg in args]\n",
    "                  for i in range(numthreads)]\n",
    "        # Spawn one thread per chunk\n",
    "        threads = [threading.Thread(target=inner_func, args=(*chunk, estado))\n",
    "                   for chunk in chunks]\n",
    "        for thread in threads:\n",
    "            thread.start()\n",
    "        for thread in threads:\n",
    "            thread.join()\n",
    "        return result\n",
    "    return func_mt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "@njit('void(double[:], double[:], int8)', nogil=True)\n",
    "def get_estado_jit_mp_template(result, pop_estado, estado):\n",
    "    for j in range(len(result)):\n",
    "        if pop_estado[j] == estado:\n",
    "            result[j] = 1\n",
    "        else:\n",
    "            result[j] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "get_estado_jit_mp = make_multithread_mod(get_estado_jit_mp_template, os.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "numthreads = os.cpu_count()\n",
    "def get_estado_jit_mp_2(pop_estado, estado):\n",
    "    length = len(pop_estado)\n",
    "    result = np.empty(length, dtype=np.float64)\n",
    "    args = (result, pop_estado)\n",
    "    chunklen = (len(pop_estado) + numthreads - 1) // numthreads\n",
    "    # Create argument tuples for each input chunk\n",
    "    chunks = [[arg[i * chunklen:(i + 1) * chunklen] for arg in args]\n",
    "              for i in range(numthreads)]\n",
    "    # Spawn one thread per chunk\n",
    "    threads = [threading.Thread(target=get_estado_jit_mp_template, args=(*chunk, estado))\n",
    "               for chunk in chunks]\n",
    "    for chunk in chunks:\n",
    "        aux = (*chunk, estado)\n",
    "    for thread in threads:\n",
    "        thread.start()\n",
    "    for thread in threads:\n",
    "        thread.join()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "@njit(parallel=True)\n",
    "def get_estado_jit_mp_prange(pop_estado, estado):\n",
    "    pop_selecionados = np.zeros_like(pop_estado)\n",
    "    for j in prange(len(pop_estado)):\n",
    "        if pop_estado[j] == estado:\n",
    "            pop_selecionados[j] = 1\n",
    "    return pop_selecionados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66.5 µs ± 18.1 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n",
      "52.2 µs ± 10.3 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n",
      "1.11 µs ± 85.6 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n",
      "1.21 µs ± 299 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n",
      "456 µs ± 7.28 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "477 µs ± 23.6 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "The slowest run took 12.04 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "21.6 µs ± 25.2 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "pop_estado = rede_completa.pop_estado_0\n",
    "\n",
    "%timeit get_estado_np_select(pop_estado, 1)\n",
    "%timeit get_estado_np_py(pop_estado, 1)\n",
    "%timeit get_estado_jit_np_py(pop_estado, 1)\n",
    "%timeit get_estado_jit_loop(pop_estado, 1)\n",
    "%timeit get_estado_jit_mp(pop_estado,1)\n",
    "%timeit get_estado_jit_mp_2(pop_estado,1)\n",
    "%timeit get_estado_jit_mp_prange(pop_estado,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Ops, multi-threading funcionou nos exemplos acima mas não nesse caso. Precisamos avaliar melhor as construções acima."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<!--NAVIGATOR-->\n",
    "\n",
    "---\n",
    "[<- Modelos individuais - convergência em redes completas](14.00.Aula-Modelos_individuais_convergencia_redes_completas.ipynb) | [Página Inicial](00.00-Pagina_Inicial.ipynb) | [Modelos individuais - reformulação da implementação ->](16.00.Aula-Modelos_individuais_reformulacao.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
