{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<!--HEADER-->\n",
    "[*Notas sobre modelagem da epidemia de Covid-19*](https://github.com/rmsrosa/modcovid19) / [*IM-UFRJ*](https://www.im.ufrj.br)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<!--BADGES-->\n",
    "<a href=\"../slides/15.00.Aula-Modelos_individuais_reformulacao.slides.html\" target=\"_blank\"><img align=\"left\" src=\"https://img.shields.io/badge/local-slides-darkgreen\" alt=\"localslides\" title=\"Local Slides\"></a>\n",
    "&nbsp;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<!--NAVIGATOR-->\n",
    "[<- Modelos individuais - convergência em redes completas](14.00.Aula-Modelos_individuais_convergencia_redes_completas.ipynb) | [Página Inicial](00.00-Pagina_Inicial.ipynb) \n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Modelos individuais - reformulação da implementação\n",
    "\n",
    "- Reformular o método para não usar grafos e acelerar a execução"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "**Importando bibliotecas e definindo funções a serem usadas abaixo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import datetime # date and time tools\n",
    "\n",
    "import os, sys\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from numba import njit, prange\n",
    "import threading\n",
    "\n",
    "import math\n",
    "from timeit import repeat\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import io, base64\n",
    "from IPython.display import Image, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "import episiming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Atualização mais recente do kernel: 19/May/2020\n"
     ]
    }
   ],
   "source": [
    "dt_string = datetime.datetime.now().strftime(\"%d/%b/%Y\")\n",
    "print(f\"Atualização mais recente do kernel: {dt_string}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "sns.set_style(\"darkgrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Gargalos\n",
    "\n",
    "### Passo de tempo\n",
    "\n",
    "Aqui o código atual de cada passo de tempo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def passo_vetorial(pop_estado, redes, redes_tx_transmissao,\n",
    "                   pop_fator_tx_transmissao_c, prob_nao_recuperacao,\n",
    "                   pop_posicoes, f_kernel, dt):\n",
    "\n",
    "    num_pop = len(pop_estado)\n",
    "\n",
    "    pop_suscetiveis = np.select([pop_estado==1], [pop_estado])\n",
    "\n",
    "    pop_infectados = np.select([pop_estado==2], [pop_estado])/2\n",
    "    \n",
    "    contatos_de_risco_rs = np.zeros([len(redes_tx_transmissao), num_pop])\n",
    "\n",
    "    for j in range(len(redes_tx_transmissao)):\n",
    "        for (i,k) in redes[j].edges:\n",
    "            if pop_infectados[k] and pop_suscetiveis[i]:\n",
    "                contatos_de_risco_rs[j][i] += 1\n",
    "            elif pop_infectados[i] and pop_suscetiveis[k]:\n",
    "                contatos_de_risco_rs[j][k] += 1\n",
    "               \n",
    "    contatos_de_risco_c = np.array(\n",
    "            [np.dot(pop_infectados,\n",
    "                    f_kernel(np.linalg.norm(pop_posicoes - pop_posicoes[i], \n",
    "                             axis=1)\n",
    "                            )\n",
    "                    )\n",
    "             for i in range(num_pop)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    \n",
    "    lambda_rate = ((redes_tx_transmissao * contatos_de_risco_rs).sum(axis=0) +\n",
    "                   pop_fator_tx_transmissao_c * contatos_de_risco_c)\n",
    "    \n",
    "    prob_nao_contagio = np.exp(-dt*lambda_rate)                             \n",
    "\n",
    "    sorteio = np.random.rand(num_pop)\n",
    "\n",
    "    pop_novos_infectados = np.select([sorteio > prob_nao_contagio], [np.ones(num_pop)])\n",
    "\n",
    "    sorteio = np.random.rand(num_pop)\n",
    "\n",
    "    pop_novos_recuperados = np.select([pop_infectados * sorteio > prob_nao_recuperacao], \n",
    "                                      [np.ones(num_pop)])\n",
    "\n",
    "    return pop_estado + pop_novos_infectados + pop_novos_recuperados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Cálculo da população\n",
    "\n",
    "O cálculo de `num_pop` a partir de `pop_estado` é ridiculamente rápido. De qualquer forma, podemos incluí-lo como argumento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165 ns ± 53.3 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n",
      "131 ns ± 19.8 ns per loop (mean ± std. dev. of 7 runs, 10000000 loops each)\n",
      "134 ns ± 0.909 ns per loop (mean ± std. dev. of 7 runs, 10000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "n_pop = 10000\n",
    "pop_estado = np.random.randint(low=1, high=3, size = n_pop)\n",
    "\n",
    "def f(a):\n",
    "    pass\n",
    "\n",
    "def g(num_pop, a):\n",
    "    pass\n",
    "\n",
    "%timeit len(pop_estado)\n",
    "\n",
    "%timeit f(pop_estado)\n",
    "%timeit g(n_pop, pop_estado)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "As linhas\n",
    "\n",
    "```python\n",
    "    pop_suscetiveis = np.select([pop_estado==1], [pop_estado])\n",
    "\n",
    "    pop_infectados = np.select([pop_estado==2], [pop_estado])/2\n",
    "    \n",
    "    contatos_de_risco_rs = np.zeros([len(redes_tx_transmissao), num_pop])\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    lambda_rate = ((redes_tx_transmissao * contatos_de_risco_rs).sum(axis=0) +\n",
    "                   pop_fator_tx_transmissao_c * contatos_de_risco_c)\n",
    "    \n",
    "    prob_nao_contagio = np.exp(-dt*lambda_rate)                             \n",
    "\n",
    "    sorteio = np.random.rand(num_pop)\n",
    "\n",
    "    pop_novos_infectados = np.select([sorteio > prob_nao_contagio], [np.ones(num_pop)])\n",
    "\n",
    "    sorteio = np.random.rand(num_pop)\n",
    "\n",
    "    pop_novos_recuperados = np.select([pop_infectados * sorteio > prob_nao_recuperacao], \n",
    "                                      [np.ones(num_pop)])\n",
    "\n",
    "    return pop_estado + pop_novos_infectados + pop_novos_recuperados\n",
    "\n",
    "```\n",
    "\n",
    "são todas tratadas diretamente pelo `numpy`, portanto, já são bastante eficientes e paralelizadas (sob condições normais do sistema).\n",
    "\n",
    "É claro que podemos ganhar mais paralelizando o conjunto todo dessas linhas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Gargalos\n",
    "\n",
    "Os dois gargalos, no entanto, estão no cálculo dos contatos de risco, tanto das redes fixas (residencial e de local de escola/trabalho) como da comunidade.\n",
    "\n",
    "O problema é que ambas envolvem ciclos *(loops)* em python. E não vejo como torná-los códigos tratados diretamente pelo `numpy`.\n",
    "\n",
    "```python\n",
    "    for j in range(len(redes_tx_transmissao)):\n",
    "        for (i,k) in redes[j].edges:\n",
    "            if pop_infectados[k] and pop_suscetiveis[i]:\n",
    "                contatos_de_risco_rs[j][i] += 1\n",
    "            elif pop_infectados[i] and pop_suscetiveis[k]:\n",
    "                contatos_de_risco_rs[j][k] += 1\n",
    "               \n",
    "    contatos_de_risco_c = np.array(\n",
    "            [np.dot(pop_infectados,\n",
    "                    f_kernel(np.linalg.norm(pop_posicoes - pop_posicoes[i], \n",
    "                             axis=1)\n",
    "                            )\n",
    "                    )\n",
    "             for i in range(num_pop)\n",
    "            ]\n",
    "        )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Custo computacional\n",
    "\n",
    "Para ilustrar o custo computacional de cada termo acima, vamos considerar o cenário de 350 habitantes usado anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "cenario_pop_350 = episiming.cenarios.Pop350()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Definindo as variáveis usadas pela função "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "dt = 1\n",
    "pop_estado = cenario_pop_350.pop_estado_0\n",
    "redes = cenario_pop_350.redes\n",
    "redes_tx_transmissao = cenario_pop_350.redes_tx_transmissao\n",
    "pop_fator_tx_transmissao_c = cenario_pop_350.pop_fator_tx_transmissao_c\n",
    "prob_nao_recuperacao = np.exp(-dt*cenario_pop_350.gamma)\n",
    "pop_posicoes = cenario_pop_350.pop_posicoes\n",
    "f_kernel = cenario_pop_350.f_kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Para o cálculo do tempo, vamos definir, ainda, funções para os códigos que consideramos \"gargalos\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def get_contatos_de_risco_rs(num_pop, pop_suscetiveis, pop_infectados, redes):\n",
    "\n",
    "    contatos_de_risco_rs = np.zeros([len(redes), num_pop])\n",
    "\n",
    "    for j in range(len(redes)):\n",
    "        for (i,k) in redes[j].edges:\n",
    "            if pop_infectados[k] and pop_suscetiveis[i]:\n",
    "                contatos_de_risco_rs[j][i] += 1\n",
    "            elif pop_infectados[i] and pop_suscetiveis[k]:\n",
    "                contatos_de_risco_rs[j][k] += 1\n",
    "    return contatos_de_risco_rs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def get_contatos_de_risco_c(pop_infectados, pop_posicoes):\n",
    "    contatos_de_risco_c = np.array(\n",
    "            [np.dot(pop_infectados,\n",
    "                    f_kernel(np.linalg.norm(pop_posicoes - pop_posicoes[i], \n",
    "                             axis=1)\n",
    "                            )\n",
    "                    )\n",
    "             for i in range(num_pop)\n",
    "            ]\n",
    "        )\n",
    "    return contatos_de_risco_c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Agora, executamos todos as linhas da função."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "num_pop = len(pop_estado)\n",
    "\n",
    "pop_suscetiveis = np.select([pop_estado==1], [pop_estado])\n",
    "\n",
    "pop_infectados = np.select([pop_estado==2], [pop_estado])/2\n",
    "\n",
    "contatos_de_risco_rs = get_contatos_de_risco_rs(num_pop, pop_suscetiveis, pop_infectados, redes)\n",
    "\n",
    "contatos_de_risco_c = get_contatos_de_risco_c(pop_infectados, pop_posicoes)\n",
    "\n",
    "lambda_rate = ((redes_tx_transmissao * contatos_de_risco_rs).sum(axis=0) + pop_fator_tx_transmissao_c * contatos_de_risco_c)\n",
    "\n",
    "prob_nao_contagio = np.exp(-dt*lambda_rate)                             \n",
    "\n",
    "sorteio = np.random.rand(num_pop)\n",
    "\n",
    "pop_novos_infectados = np.select([sorteio > prob_nao_contagio], [np.ones(num_pop)])\n",
    "\n",
    "sorteio = np.random.rand(num_pop)\n",
    "\n",
    "pop_novos_recuperados = np.select([pop_infectados * sorteio > prob_nao_recuperacao], [np.ones(num_pop)])\n",
    "\n",
    "pop_novo_estado = pop_estado + pop_novos_infectados + pop_novos_recuperados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Com todas as variáveis já calculadas e gravadas na memória, façamos as contagens de tempo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104 ns ± 1.37 ns per loop (mean ± std. dev. of 7 runs, 10000000 loops each)\n",
      "54.2 µs ± 1.2 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n",
      "56.4 µs ± 594 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n",
      "1.88 ms ± 12.9 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "17.9 ms ± 115 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "15.3 µs ± 904 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n",
      "6.53 µs ± 67.9 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n",
      "6.2 µs ± 83.4 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n",
      "58 µs ± 1.55 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n",
      "6.15 µs ± 66.2 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n",
      "65.9 µs ± 6.51 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n",
      "2.29 µs ± 43.3 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit num_pop = len(pop_estado)\n",
    "\n",
    "%timeit pop_suscetiveis = np.select([pop_estado==1], [pop_estado])\n",
    "\n",
    "%timeit pop_infectados = np.select([pop_estado==2], [pop_estado])/2\n",
    "\n",
    "%timeit contatos_de_risco_rs = get_contatos_de_risco_rs(num_pop, pop_suscetiveis, pop_infectados, redes)\n",
    "\n",
    "%timeit contatos_de_risco_c = get_contatos_de_risco_c(pop_infectados, pop_posicoes)\n",
    "\n",
    "%timeit lambda_rate = ((redes_tx_transmissao * contatos_de_risco_rs).sum(axis=0) + pop_fator_tx_transmissao_c * contatos_de_risco_c)\n",
    "\n",
    "%timeit prob_nao_contagio = np.exp(-dt*lambda_rate)                             \n",
    "\n",
    "%timeit sorteio = np.random.rand(num_pop)\n",
    "\n",
    "%timeit pop_novos_infectados = np.select([sorteio > prob_nao_contagio], [np.ones(num_pop)])\n",
    "\n",
    "%timeit sorteio = np.random.rand(num_pop)\n",
    "\n",
    "%timeit pop_novos_recuperados = np.select([pop_infectados * sorteio > prob_nao_recuperacao], [np.ones(num_pop)])\n",
    "\n",
    "%timeit pop_novo_estado = pop_estado + pop_novos_infectados + pop_novos_recuperados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Na função toda, gastamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.5 ms ± 416 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit passo_vetorial(pop_estado, redes, redes_tx_transmissao, pop_fator_tx_transmissao_c, prob_nao_recuperacao, pop_posicoes, f_kernel, dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Observe que os cálculos além dos dos contatos de risco têm um custo negligível perto desses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Numba JIT\n",
    "\n",
    "Uma opção é usar o [numba](http://numba.pydata.org/numba-doc/latest/index.html) (veja [A ~5 minute guide to Numba](http://numba.pydata.org/numba-doc/latest/user/5minguide.html)), que é um compilador \"just-in-time\", capaz de transformar um certo conjunto de instruções em python e em numpy diretamente em código executável, no momento da definição da função.\n",
    "\n",
    "A partir daí, qualquer chamada à função irá executar o código compilado da função."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Numba jit na rede de contatos\n",
    "\n",
    "Para simplificar, vamos considerar o cenário de uma rede completa e analisar o tempo necessário para executar diferentes versões do cálculo dos contatos de risco, incluindo versões com o `numba.jit`.\n",
    "\n",
    "Para usar o `numba.jit`, vamos importar o método `njit`, que é o `jit` com a opção `nopython = True`. Esta opção evita que o código \"recaia\" para o python interpretado caso não consiga compilar alguma parte. Vale lembrar, aqui, que só uma parte dos métodos, funções e objetos do python padrão e do numpy funcionam adequadamente no `numba`.\n",
    "\n",
    "Para simplificar ainda mais, vamos assumir, como no caso da rede completa, que há somente uma rede."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "num_pop = 60\n",
    "num_infectados_0 = 6\n",
    "beta = 0.5\n",
    "gamma = 0.2\n",
    "\n",
    "rede_completa = episiming.cenarios.RedeCompleta(num_pop, num_infectados_0, beta, gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "pop_estado = rede_completa.pop_estado_0\n",
    "rede = rede_completa.redes[0]\n",
    "pop_suscetiveis = np.select([pop_estado==1], [pop_estado])\n",
    "pop_infectados = np.select([pop_estado==2], [pop_estado])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def get_contatos_de_risco_nx(num_pop, rede, pop_suscetiveis, pop_infectados):\n",
    "\n",
    "    contatos_de_risco = np.zeros(num_pop)\n",
    "\n",
    "    for (i,k) in rede.edges:\n",
    "        if pop_infectados[k] and pop_suscetiveis[i]:\n",
    "            contatos_de_risco[i] += 1\n",
    "        elif pop_infectados[i] and pop_suscetiveis[k]:\n",
    "            contatos_de_risco[k] += 1\n",
    "\n",
    "    return contatos_de_risco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def get_contatos_de_risco_py(num_pop, pop_suscetiveis, pop_infectados):\n",
    "    contatos_de_risco = np.zeros(num_pop)\n",
    "    for i in range(num_pop):\n",
    "        for k in range(i):\n",
    "            if pop_infectados[k] and pop_suscetiveis[i]:\n",
    "                contatos_de_risco[i] += 1\n",
    "            elif pop_infectados[i] and pop_suscetiveis[k]:\n",
    "                contatos_de_risco[k] += 1\n",
    "    return contatos_de_risco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "@njit\n",
    "def get_contatos_de_risco_jit(num_pop, pop_suscetiveis, pop_infectados):\n",
    "    contatos_de_risco = np.zeros(num_pop)\n",
    "    for i in range(num_pop):\n",
    "        for k in range(i):\n",
    "            if pop_infectados[k] and pop_suscetiveis[i]:\n",
    "                contatos_de_risco[i] += 1\n",
    "            elif pop_infectados[i] and pop_suscetiveis[k]:\n",
    "                contatos_de_risco[k] += 1\n",
    "    return contatos_de_risco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6., 6., 6., 6., 6., 6., 6., 6., 6., 0., 6., 6., 6., 6., 6., 6., 6.,\n",
       "       6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 0., 6., 0., 6., 6.,\n",
       "       0., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 0., 6., 6., 6.,\n",
       "       6., 6., 6., 6., 0., 6., 6., 6., 6.])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conexoes = list(rede.edges)\n",
    "def get_contatos_de_risco_cx(num_pop, conexoes, pop_suscetiveis, pop_infectados):\n",
    "    contatos_de_risco = np.zeros(num_pop)\n",
    "    for i, k in conexoes:\n",
    "            if pop_infectados[k] and pop_suscetiveis[i]:\n",
    "                contatos_de_risco[i] += 1\n",
    "            elif pop_infectados[i] and pop_suscetiveis[k]:\n",
    "                contatos_de_risco[k] += 1\n",
    "    return contatos_de_risco\n",
    "get_contatos_de_risco_cx(num_pop, conexoes, pop_suscetiveis, pop_infectados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "@njit\n",
    "def get_contatos_de_risco_cx_jit(num_pop, conexoes, pop_suscetiveis, pop_infectados):\n",
    "    contatos_de_risco = np.zeros(num_pop)\n",
    "    for i, k in conexoes:\n",
    "            if pop_infectados[k] and pop_suscetiveis[i]:\n",
    "                contatos_de_risco[i] += 1\n",
    "            elif pop_infectados[i] and pop_suscetiveis[k]:\n",
    "                contatos_de_risco[k] += 1\n",
    "    return contatos_de_risco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from numba.typed import List\n",
    "typed_conexoes = List()\n",
    "[typed_conexoes.append(x) for x in conexoes]\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.51 ms ± 18.7 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "1.08 ms ± 14.9 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "5.31 µs ± 47.1 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n",
      "1.1 ms ± 8.64 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "16.4 µs ± 181 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit get_contatos_de_risco_nx(num_pop, rede, pop_suscetiveis, pop_infectados)\n",
    "%timeit get_contatos_de_risco_py(num_pop, pop_suscetiveis, pop_infectados)\n",
    "%timeit get_contatos_de_risco_jit(num_pop, pop_suscetiveis, pop_infectados)\n",
    "%timeit get_contatos_de_risco_cx(num_pop, conexoes, pop_suscetiveis, pop_infectados)\n",
    "%timeit get_contatos_de_risco_cx_jit(num_pop, typed_conexoes, pop_suscetiveis, pop_infectados)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Assim, conseguimor baixar o custo computacional (nesta máquina e neste cenário) do cálculo das conexões de risco da rede de contatos de quase $1.45 \\,\\texttt{ms}$ para algo da ordem de $5 \\,\\mu\\texttt{s}$, usando `get_contatos_de_risco_jit`. Isso é uma redução dramática para menos de $0,4\\%$ em comparação com o custo atual."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Numba jit na seleção de suscetíveis e infectados\n",
    "\n",
    "Após reduzir de milisegundos a microsegundos o custo computacional do cálculo dos contatos de risco na rede social, podemos pensar em acelerar as outras partes, também.\n",
    "\n",
    "O termo mais custoso (contatos com a comunidade) deixaremos para depois. Abaixo, analisamos a aceleração do código de seleção de infectados e suscetíveis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def get_estado_np_select(pop_estado, estado):\n",
    "    return np.select([pop_estado==estado], [pop_estado])/estado\n",
    "\n",
    "def get_estado_np_py(pop_estado, estado):\n",
    "    return np.array([1 if e == estado else 0 for e in pop_estado])\n",
    "\n",
    "@njit\n",
    "def get_estado_jit_np_py(pop_estado, estado):\n",
    "    return np.array([1 if e == estado else 0 for e in pop_estado])\n",
    "\n",
    "@njit\n",
    "def get_estado_jit_loop(pop_estado, estado):\n",
    "    pop_selecionados = np.zeros_like(pop_estado)\n",
    "    for j in range(len(pop_estado)):\n",
    "        if pop_estado[j] == estado:\n",
    "            pop_selecionados[j] = 1\n",
    "    return pop_selecionados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55.6 µs ± 1.16 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n",
      "45.9 µs ± 7.74 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n",
      "1.27 µs ± 413 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n",
      "1.14 µs ± 112 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "pop_estado = rede_completa.pop_estado_0\n",
    "\n",
    "%timeit get_estado_np_select(pop_estado, 1)\n",
    "%timeit get_estado_np_py(pop_estado, 1)\n",
    "%timeit get_estado_jit_np_py(pop_estado, 1)\n",
    "%timeit get_estado_jit_loop(pop_estado, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Excelente! O `jit` reduziu sensivelmente o custo desse cálculo, também."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Paralelização com o numba\n",
    "\n",
    "Podemos buscar uma aceleração maior ainda implementando alguma forma de paralelização.\n",
    "\n",
    "A seguir, analisamos duas opções."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Paralelização com numba jit e *multi-threading*\n",
    "\n",
    "Podemos combinar o `numba` com multiprocessamento via [threading](https://docs.python.org/3/library/threading.html).\n",
    "\n",
    "Vamos começar com um exemplo adaptado de [Numba: Multi-threading](http://numba.pydata.org/numba-doc/dev/user/examples.html#multi-threading), para ver como ele se sai nessa máquina.\n",
    "\n",
    "Primeiro, montamos uma função que serve de \"envelope\" *(wrapper)*, para paralelizar qualquer função que tenha a característica que agir em cada componente de um *array* separadamente *(element-wise)*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def timefunc(correct, s, func, *args, **kwargs):\n",
    "    \"\"\"\n",
    "    Benchmark *func* and print out its runtime.\n",
    "    \"\"\"\n",
    "    print(s.ljust(20), end=\" \")\n",
    "    # Make sure the function is compiled before we start the benchmark\n",
    "    res = func(*args, **kwargs)\n",
    "    if correct is not None:\n",
    "        assert np.allclose(res, correct), (res, correct)\n",
    "    # time it\n",
    "    print('{:>5.0f} ms'.format(min(repeat(lambda: func(*args, **kwargs),\n",
    "                                          number=5, repeat=2)) * 1000))\n",
    "    return res\n",
    "\n",
    "def make_singlethread(inner_func):\n",
    "    \"\"\"\n",
    "    Run the given function inside a single thread.\n",
    "    \"\"\"\n",
    "    def func(*args):\n",
    "        length = len(args[0])\n",
    "        result = np.empty(length, dtype=np.float64)\n",
    "        inner_func(result, *args)\n",
    "        return result\n",
    "    return func\n",
    "\n",
    "def make_multithread(inner_func, numthreads):\n",
    "    \"\"\"\n",
    "    Run the given function inside *numthreads* threads, splitting its\n",
    "    arguments into equal-sized chunks.\n",
    "    \"\"\"\n",
    "    def func_mt(*args):\n",
    "        length = len(args[0])\n",
    "        result = np.empty(length, dtype=np.float64)\n",
    "        args = (result,) + args\n",
    "        chunklen = (length + numthreads - 1) // numthreads\n",
    "        # Create argument tuples for each input chunk\n",
    "        chunks = [[arg[i * chunklen:(i + 1) * chunklen] for arg in args]\n",
    "                  for i in range(numthreads)]\n",
    "        # Spawn one thread per chunk\n",
    "        threads = [threading.Thread(target=inner_func, args=chunk)\n",
    "                   for chunk in chunks]\n",
    "        for thread in threads:\n",
    "            thread.start()\n",
    "        for thread in threads:\n",
    "            thread.join()\n",
    "        return result\n",
    "    return func_mt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Agora, definimos duas versões de uma função de teste, uma para usar apenas `numpy` e outra para o `numba`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def func_np(a, b):\n",
    "    \"\"\"\n",
    "    Control function using Numpy.\n",
    "    \"\"\"\n",
    "    return np.exp(2.1 * a + 3.2 * b)\n",
    "\n",
    "@njit('void(double[:], double[:], double[:])', nogil=True)\n",
    "def inner_func_nb(result, a, b):\n",
    "    \"\"\"\n",
    "    Function under test.\n",
    "    \"\"\"\n",
    "    for i in range(len(result)):\n",
    "        result[i] = math.exp(2.1 * a[i] + 3.2 * b[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy (1 thread)        88 ms\n",
      "numba (1 thread)        65 ms\n",
      "numba (2 thread)        45 ms\n",
      "numba (3 thread)        37 ms\n",
      "numba (4 thread)        34 ms\n"
     ]
    }
   ],
   "source": [
    "nthreads = os.cpu_count()\n",
    "size = 10**6\n",
    "\n",
    "a = np.random.rand(size)\n",
    "b = np.random.rand(size)\n",
    "\n",
    "func_nb = make_singlethread(inner_func_nb)\n",
    "func_nb_mt = [make_multithread(inner_func_nb, n+1) for n in range(nthreads)]\n",
    "\n",
    "correct = timefunc(None, \"numpy (1 thread)\", func_np, a, b)\n",
    "\n",
    "for n in range(nthreads):\n",
    "    timefunc(correct, f\"numba ({n+1} thread)\", func_nb_mt[n], a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Usando `%timeit`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.6 ms ± 97.7 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "13.3 ms ± 150 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "7.54 ms ± 116 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "7.23 ms ± 70.3 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "7.32 ms ± 234 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit func_np(a, b)\n",
    "\n",
    "for n in range(nthreads):\n",
    "    %timeit func_nb_mt[n](a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "@njit\n",
    "def inner_func_nb_jit(a, b):\n",
    "    \"\"\"\n",
    "    Function under test.\n",
    "    \"\"\"\n",
    "    result = np.zeros_like(a)\n",
    "    for i in range(len(result)):\n",
    "        result[i] = math.exp(2.1 * a[i] + 3.2 * b[i])\n",
    "    return result\n",
    "\n",
    "@njit('void(double[:], double[:], double[:])', nogil=True)\n",
    "def inner_func_nb_jit_mt_template(result, a, b):\n",
    "    \"\"\"\n",
    "    Function under test.\n",
    "    \"\"\"\n",
    "    for i in range(len(result)):\n",
    "        result[i] = math.exp(2.1 * a[i] + 3.2 * b[i])\n",
    "\n",
    "inner_func_nb_jit_mt = [make_multithread(inner_func_nb_jit_mt_template, j+1) \n",
    "                          for j in range(os.cpu_count())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempos de np, jit, e jit_mt com 1, 2, 3 e 4 threads\n",
      "17.5 ms ± 188 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "12.9 ms ± 82 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "13.5 ms ± 553 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "7.55 ms ± 92.9 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "7.3 ms ± 168 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "6.99 ms ± 94 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "print('Tempos de np, jit, e jit_mt com 1, 2, 3 e 4 threads')\n",
    "%timeit func_np(a,b)\n",
    "%timeit inner_func_nb_jit(a,b)\n",
    "for j in range(os.cpu_count()):\n",
    "    %timeit inner_func_nb_jit_mt[j](a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Ok, é claro que é possível acelerar o código paralelizando via `numba.jit`. Mas parece que ele só usou 2 *cores* adequadamente, não aproveitando que são 2 *threads* por *core* por CPU. E também há a questão do *overhead*.\n",
    "\n",
    "Em relação a *cores* vs *threads*, veja [Optimizing CPU options - CPU cores and threads per CPU core per instance type](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/instance-optimize-cpu.html#cpu-options-supported-instances-values)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Paralelização com numba jit e *prange*\n",
    "\n",
    "Outra opção é via [prange](https://numba.pydata.org/numba-doc/dev/user/parallel.html#explicit-parallel-loops) *(parallel range)* do próprio `numba`, com a opção `parallel=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "@njit(parallel=False)\n",
    "def range_test(a):\n",
    "    s = 0\n",
    "    # Without \"parallel=True\" in the jit-decorator\n",
    "    # the prange statement is equivalent to range\n",
    "    for i in range(a.shape[0]):\n",
    "        s += a[i]\n",
    "    return s\n",
    "\n",
    "@njit(parallel=True)\n",
    "def prange_test(a):\n",
    "    s = 0\n",
    "    # Without \"parallel=True\" in the jit-decorator\n",
    "    # the prange statement is equivalent to range\n",
    "    for i in prange(a.shape[0]):\n",
    "        s += a[i]\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "186 µs ± 893 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n",
      "96.3 µs ± 27.3 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "a = np.random.rand(100000)\n",
    "%timeit range_test(a)\n",
    "%timeit prange_test(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Numba jit em paralelo na seleção de suscetíveis e infectados\n",
    "\n",
    "Com essa paralelização em mente, podemos ver se conseguimos reduzir ainda mais os códigos de seleção de infectados e suscetíveis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def make_multithread_mod(inner_func, numthreads):\n",
    "    \"\"\"\n",
    "    Run the given function inside *numthreads* threads, splitting its\n",
    "    arguments into equal-sized chunks.\n",
    "    \"\"\"\n",
    "    def func_mt(pop_estado, estado):\n",
    "        length = len(pop_estado)\n",
    "        result = np.empty(length, dtype=np.float64)\n",
    "        args = (result, pop_estado)\n",
    "        chunklen = (length + numthreads - 1) // numthreads\n",
    "        # Create argument tuples for each input chunk\n",
    "        chunks = [[arg[i * chunklen:(i + 1) * chunklen] for arg in args]\n",
    "                  for i in range(numthreads)]\n",
    "        # Spawn one thread per chunk\n",
    "        threads = [threading.Thread(target=inner_func, args=(*chunk, estado))\n",
    "                   for chunk in chunks]\n",
    "        for thread in threads:\n",
    "            thread.start()\n",
    "        for thread in threads:\n",
    "            thread.join()\n",
    "        return result\n",
    "    return func_mt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "@njit('void(double[:], double[:], int8)', nogil=True)\n",
    "def get_estado_jit_mp_template(result, pop_estado, estado):\n",
    "    for j in range(len(result)):\n",
    "        if pop_estado[j] == estado:\n",
    "            result[j] = 1\n",
    "        else:\n",
    "            result[j] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "get_estado_jit_mp = make_multithread_mod(get_estado_jit_mp_template, os.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "numthreads = os.cpu_count()\n",
    "def get_estado_jit_mp_2(pop_estado, estado):\n",
    "    length = len(pop_estado)\n",
    "    result = np.empty(length, dtype=np.float64)\n",
    "    args = (result, pop_estado)\n",
    "    chunklen = (len(pop_estado) + numthreads - 1) // numthreads\n",
    "    # Create argument tuples for each input chunk\n",
    "    chunks = [[arg[i * chunklen:(i + 1) * chunklen] for arg in args]\n",
    "              for i in range(numthreads)]\n",
    "    # Spawn one thread per chunk\n",
    "    threads = [threading.Thread(target=get_estado_jit_mp_template, args=(*chunk, estado))\n",
    "               for chunk in chunks]\n",
    "    for chunk in chunks:\n",
    "        aux = (*chunk, estado)\n",
    "    for thread in threads:\n",
    "        thread.start()\n",
    "    for thread in threads:\n",
    "        thread.join()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "@njit(parallel=True)\n",
    "def get_estado_jit_mp_prange(pop_estado, estado):\n",
    "    pop_selecionados = np.zeros_like(pop_estado)\n",
    "    for j in prange(len(pop_estado)):\n",
    "        if pop_estado[j] == estado:\n",
    "            pop_selecionados[j] = 1\n",
    "    return pop_selecionados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55.6 µs ± 686 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n",
      "40.6 µs ± 650 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n",
      "1 µs ± 10.1 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n",
      "1.02 µs ± 11.8 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n",
      "460 µs ± 10.5 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "456 µs ± 7.54 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "The slowest run took 6.80 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "12.7 µs ± 13 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "pop_estado = rede_completa.pop_estado_0\n",
    "\n",
    "%timeit get_estado_np_select(pop_estado, 1)\n",
    "%timeit get_estado_np_py(pop_estado, 1)\n",
    "%timeit get_estado_jit_np_py(pop_estado, 1)\n",
    "%timeit get_estado_jit_loop(pop_estado, 1)\n",
    "%timeit get_estado_jit_mp(pop_estado,1)\n",
    "%timeit get_estado_jit_mp_2(pop_estado,1)\n",
    "%timeit get_estado_jit_mp_prange(pop_estado,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Ops, multi-threading funcionou nos exemplos acima mas não nesse caso. Precisamos avaliar melhor as construções acima."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<!--NAVIGATOR-->\n",
    "\n",
    "---\n",
    "[<- Modelos individuais - convergência em redes completas](14.00.Aula-Modelos_individuais_convergencia_redes_completas.ipynb) | [Página Inicial](00.00-Pagina_Inicial.ipynb) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
